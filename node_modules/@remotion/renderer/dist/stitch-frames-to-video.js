"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.stitchFramesToVideo = exports.internalStitchFramesToVideo = void 0;
const node_fs_1 = __importStar(require("node:fs"));
const node_path_1 = __importDefault(require("node:path"));
const remotion_1 = require("remotion");
const calculate_asset_positions_1 = require("./assets/calculate-asset-positions");
const convert_assets_to_file_urls_1 = require("./assets/convert-assets-to-file-urls");
const download_and_map_assets_to_file_1 = require("./assets/download-and-map-assets-to-file");
const audio_codec_1 = require("./audio-codec");
const call_ffmpeg_1 = require("./call-ffmpeg");
const codec_1 = require("./codec");
const codec_supports_media_1 = require("./codec-supports-media");
const convert_number_of_gif_loops_to_ffmpeg_1 = require("./convert-number-of-gif-loops-to-ffmpeg");
const crf_1 = require("./crf");
const delete_directory_1 = require("./delete-directory");
const does_have_m2_bug_1 = require("./does-have-m2-bug");
const find_closest_package_json_1 = require("./find-closest-package-json");
const get_codec_name_1 = require("./get-codec-name");
const get_extension_from_codec_1 = require("./get-extension-from-codec");
const get_prores_profile_name_1 = require("./get-prores-profile-name");
const logger_1 = require("./logger");
const make_cancel_signal_1 = require("./make-cancel-signal");
const merge_audio_track_1 = require("./merge-audio-track");
const parse_ffmpeg_progress_1 = require("./parse-ffmpeg-progress");
const pixel_format_1 = require("./pixel-format");
const preprocess_audio_track_1 = require("./preprocess-audio-track");
const prores_profile_1 = require("./prores-profile");
const truthy_1 = require("./truthy");
const validate_even_dimensions_with_codec_1 = require("./validate-even-dimensions-with-codec");
const validate_videobitrate_1 = require("./validate-videobitrate");
const packageJsonPath = node_path_1.default.join(__dirname, '..', 'package.json');
const packageJson = node_fs_1.default.existsSync(packageJsonPath)
    ? JSON.parse(node_fs_1.default.readFileSync(packageJsonPath, 'utf-8'))
    : null;
const getAssetsData = async ({ assets, onDownload, fps, expectedFrames, verbose, onProgress, downloadMap, remotionRoot, indent, }) => {
    const fileUrlAssets = await (0, convert_assets_to_file_urls_1.convertAssetsToFileUrls)({
        assets,
        onDownload: onDownload !== null && onDownload !== void 0 ? onDownload : (() => () => undefined),
        downloadMap,
    });
    (0, download_and_map_assets_to_file_1.markAllAssetsAsDownloaded)(downloadMap);
    const assetPositions = (0, calculate_asset_positions_1.calculateAssetPositions)(fileUrlAssets);
    logger_1.Log.verboseAdvanced({ indent, logLevel: verbose ? 'verbose' : 'info', tag: 'audio' }, 'asset positions', JSON.stringify(assetPositions));
    const preprocessProgress = new Array(assetPositions.length).fill(0);
    const updateProgress = () => {
        onProgress(preprocessProgress.reduce((a, b) => a + b, 0) / assetPositions.length);
    };
    const preprocessed = (await Promise.all(assetPositions.map(async (asset, index) => {
        const filterFile = node_path_1.default.join(downloadMap.audioMixing, `${index}.wav`);
        const result = await (0, preprocess_audio_track_1.preprocessAudioTrack)({
            outName: filterFile,
            asset,
            expectedFrames,
            fps,
            downloadMap,
        });
        preprocessProgress[index] = 1;
        updateProgress();
        return result;
    }))).filter(truthy_1.truthy);
    const outName = node_path_1.default.join(downloadMap.audioPreprocessing, `audio.wav`);
    await (0, merge_audio_track_1.mergeAudioTrack)({
        files: preprocessed,
        outName,
        numberOfSeconds: Number((expectedFrames / fps).toFixed(3)),
        downloadMap,
        remotionRoot,
    });
    onProgress(1);
    (0, delete_directory_1.deleteDirectory)(downloadMap.audioMixing);
    preprocessed.forEach((p) => {
        (0, delete_directory_1.deleteDirectory)(p.outName);
    });
    return outName;
};
const innerStitchFramesToVideo = async ({ assetsInfo, audioBitrate, audioCodec, cancelSignal, codec, crf, dir, enforceAudioTrack, ffmpegOverride, force, fps, height, indent, muted, onDownload, outputLocation, pixelFormat, preEncodedFileLocation, preferLossless, proResProfile, verbose, videoBitrate, width, numberOfGifLoops, onProgress, }, remotionRoot) => {
    var _a;
    remotion_1.Internals.validateDimension(height, 'height', 'passed to `stitchFramesToVideo()`');
    remotion_1.Internals.validateDimension(width, 'width', 'passed to `stitchFramesToVideo()`');
    (0, validate_even_dimensions_with_codec_1.validateEvenDimensionsWithCodec)({
        width,
        height,
        codec,
        scale: 1,
    });
    (0, prores_profile_1.validateSelectedCodecAndProResCombination)({
        codec,
        proResProfile,
    });
    (0, validate_videobitrate_1.validateBitrate)(audioBitrate, 'audioBitrate');
    (0, validate_videobitrate_1.validateBitrate)(videoBitrate, 'videoBitrate');
    remotion_1.Internals.validateFps(fps, 'in `stitchFramesToVideo()`', false);
    const encoderName = (0, get_codec_name_1.getCodecName)(codec);
    const proResProfileName = (0, get_prores_profile_name_1.getProResProfileName)(codec, proResProfile);
    const mediaSupport = (0, codec_supports_media_1.codecSupportsMedia)(codec);
    const shouldRenderAudio = mediaSupport.audio &&
        (assetsInfo.assets.flat(1).length > 0 || enforceAudioTrack) &&
        !muted;
    const shouldRenderVideo = mediaSupport.video;
    if (!shouldRenderAudio && !shouldRenderVideo) {
        throw new Error('The output format has neither audio nor video. This can happen if you are rendering an audio codec and the output file has no audio or the muted flag was passed.');
    }
    // Explanation: https://github.com/remotion-dev/remotion/issues/1647
    const resolvedAudioCodec = preferLossless
        ? (0, audio_codec_1.getDefaultAudioCodec)({ codec, preferLossless: true })
        : audioCodec !== null && audioCodec !== void 0 ? audioCodec : (0, audio_codec_1.getDefaultAudioCodec)({ codec, preferLossless: false });
    const tempFile = outputLocation
        ? null
        : node_path_1.default.join(assetsInfo.downloadMap.stitchFrames, `out.${(0, get_extension_from_codec_1.getFileExtensionFromCodec)(codec, resolvedAudioCodec)}`);
    logger_1.Log.verboseAdvanced({
        indent,
        logLevel: verbose ? 'verbose' : 'info',
        tag: 'stitchFramesToVideo()',
    }, 'encoder', encoderName);
    logger_1.Log.verboseAdvanced({
        indent,
        logLevel: verbose ? 'verbose' : 'info',
        tag: 'stitchFramesToVideo()',
    }, 'audioCodec', resolvedAudioCodec);
    logger_1.Log.verboseAdvanced({
        indent,
        logLevel: verbose ? 'verbose' : 'info',
        tag: 'stitchFramesToVideo()',
    }, 'pixelFormat', pixelFormat);
    logger_1.Log.verboseAdvanced({
        indent,
        logLevel: verbose ? 'verbose' : 'info',
        tag: 'stitchFramesToVideo()',
    }, 'codec', codec);
    logger_1.Log.verboseAdvanced({
        indent,
        logLevel: verbose ? 'verbose' : 'info',
        tag: 'stitchFramesToVideo()',
    }, 'shouldRenderAudio', shouldRenderAudio);
    logger_1.Log.verboseAdvanced({
        indent,
        logLevel: verbose ? 'verbose' : 'info',
        tag: 'stitchFramesToVideo()',
    }, 'shouldRenderVideo', shouldRenderVideo);
    logger_1.Log.verboseAdvanced({
        indent,
        logLevel: verbose ? 'verbose' : 'info',
        tag: 'stitchFramesToVideo()',
    }, 'proResProfileName', proResProfileName);
    (0, crf_1.validateQualitySettings)({
        crf,
        codec,
        videoBitrate,
    });
    (0, pixel_format_1.validateSelectedPixelFormatAndCodecCombination)(pixelFormat, codec);
    const expectedFrames = assetsInfo.assets.length;
    const updateProgress = (preStitchProgress, muxProgress) => {
        const totalFrameProgress = 0.5 * preStitchProgress * expectedFrames + muxProgress * 0.5;
        onProgress === null || onProgress === void 0 ? void 0 : onProgress(Math.round(totalFrameProgress));
    };
    const audio = shouldRenderAudio
        ? await getAssetsData({
            assets: assetsInfo.assets,
            onDownload,
            fps,
            expectedFrames,
            verbose,
            onProgress: (prog) => updateProgress(prog, 0),
            downloadMap: assetsInfo.downloadMap,
            remotionRoot,
            indent,
        })
        : null;
    if (mediaSupport.audio && !mediaSupport.video) {
        if (!resolvedAudioCodec) {
            throw new TypeError('exporting audio but has no audio codec name. Report this in the Remotion repo.');
        }
        const ffmpegTask = (0, call_ffmpeg_1.callFf)('ffmpeg', [
            '-i',
            audio,
            '-c:a',
            (0, audio_codec_1.mapAudioCodecToFfmpegAudioCodecName)(resolvedAudioCodec),
            // Set bitrate up to 320k, for aac it might effectively be lower
            '-b:a',
            audioBitrate !== null && audioBitrate !== void 0 ? audioBitrate : '320k',
            force ? '-y' : null,
            outputLocation !== null && outputLocation !== void 0 ? outputLocation : tempFile,
        ].filter(remotion_1.Internals.truthy));
        cancelSignal === null || cancelSignal === void 0 ? void 0 : cancelSignal(() => {
            ffmpegTask.kill();
        });
        await ffmpegTask;
        onProgress === null || onProgress === void 0 ? void 0 : onProgress(expectedFrames);
        if (audio) {
            (0, delete_directory_1.deleteDirectory)(node_path_1.default.dirname(audio));
        }
        const file = await new Promise((resolve, reject) => {
            if (tempFile) {
                node_fs_1.promises
                    .readFile(tempFile)
                    .then((f) => {
                    return resolve(f);
                })
                    .catch((e) => reject(e));
            }
            else {
                resolve(null);
            }
        });
        (0, delete_directory_1.deleteDirectory)(assetsInfo.downloadMap.stitchFrames);
        return {
            getLogs: () => '',
            task: Promise.resolve(file),
        };
    }
    const ffmpegArgs = [
        ...(preEncodedFileLocation
            ? [['-i', preEncodedFileLocation]]
            : [
                ['-r', String(fps)],
                ['-f', 'image2'],
                ['-s', `${width}x${height}`],
                ['-start_number', String(assetsInfo.firstFrameIndex)],
                ['-i', assetsInfo.imageSequenceName],
            ]),
        audio ? ['-i', audio] : null,
        numberOfGifLoops === null
            ? null
            : ['-loop', (0, convert_number_of_gif_loops_to_ffmpeg_1.convertNumberOfGifLoopsToFfmpegSyntax)(numberOfGifLoops)],
        // -c:v is the same as -vcodec as -codec:video
        // and specified the video codec.
        ['-c:v', encoderName],
        ...(preEncodedFileLocation
            ? []
            : [
                proResProfileName ? ['-profile:v', proResProfileName] : null,
                ['-pix_fmt', pixelFormat],
                // Without explicitly disabling auto-alt-ref,
                // transparent WebM generation doesn't work
                pixelFormat === 'yuva420p' ? ['-auto-alt-ref', '0'] : null,
                ...(0, crf_1.validateQualitySettings)({
                    crf,
                    videoBitrate,
                    codec,
                }),
            ]),
        codec === 'h264' ? ['-movflags', 'faststart'] : null,
        resolvedAudioCodec
            ? ['-c:a', (0, audio_codec_1.mapAudioCodecToFfmpegAudioCodecName)(resolvedAudioCodec)]
            : null,
        // Set max bitrate up to 1024kbps, will choose lower if that's too much
        resolvedAudioCodec ? ['-b:a', audioBitrate || '512K'] : null,
        // Ignore metadata that may come from remote media
        ['-map_metadata', '-1'],
        [
            '-metadata',
            `comment=` +
                [`Made with Remotion`, packageJson ? packageJson.version : null].join(' '),
        ],
        force ? '-y' : null,
        outputLocation !== null && outputLocation !== void 0 ? outputLocation : tempFile,
    ];
    const ffmpegString = ffmpegArgs.flat(2).filter(Boolean);
    const finalFfmpegString = ffmpegOverride
        ? ffmpegOverride({ type: 'stitcher', args: ffmpegString })
        : ffmpegString;
    logger_1.Log.verboseAdvanced({
        indent: indent !== null && indent !== void 0 ? indent : false,
        logLevel: verbose ? 'verbose' : 'info',
        tag: 'stitchFramesToVideo()',
    }, 'Generated final FFMPEG command:');
    logger_1.Log.verboseAdvanced({
        indent,
        logLevel: verbose ? 'verbose' : 'info',
        tag: 'stitchFramesToVideo()',
    }, finalFfmpegString.join(' '));
    const task = (0, call_ffmpeg_1.callFf)('ffmpeg', finalFfmpegString, {
        cwd: dir,
    });
    cancelSignal === null || cancelSignal === void 0 ? void 0 : cancelSignal(() => {
        task.kill();
    });
    let ffmpegOutput = '';
    let isFinished = false;
    (_a = task.stderr) === null || _a === void 0 ? void 0 : _a.on('data', (data) => {
        var _a;
        const str = data.toString();
        ffmpegOutput += str;
        if (onProgress) {
            const parsed = (0, parse_ffmpeg_progress_1.parseFfmpegProgress)(str);
            // FFMPEG bug: In some cases, FFMPEG does hang after it is finished with it's job
            // Example repo: https://github.com/JonnyBurger/ffmpeg-repro (access can be given upon request)
            if (parsed !== undefined) {
                // If two times in a row the finishing frame is logged, we quit the render
                if (parsed === expectedFrames) {
                    if (isFinished) {
                        (_a = task.stdin) === null || _a === void 0 ? void 0 : _a.write('q');
                    }
                    else {
                        isFinished = true;
                    }
                }
                updateProgress(1, parsed);
            }
        }
    });
    return {
        task: task.then(() => {
            (0, delete_directory_1.deleteDirectory)(assetsInfo.downloadMap.audioPreprocessing);
            if (tempFile === null) {
                (0, delete_directory_1.deleteDirectory)(assetsInfo.downloadMap.stitchFrames);
                return null;
            }
            return node_fs_1.promises
                .readFile(tempFile)
                .then((file) => {
                return Promise.all([
                    file,
                    (0, delete_directory_1.deleteDirectory)(node_path_1.default.dirname(tempFile)),
                    (0, delete_directory_1.deleteDirectory)(assetsInfo.downloadMap.stitchFrames),
                ]);
            })
                .then(([file]) => file);
        }),
        getLogs: () => ffmpegOutput,
    };
};
const internalStitchFramesToVideo = async (options) => {
    const remotionRoot = (0, find_closest_package_json_1.findRemotionRoot)();
    (0, does_have_m2_bug_1.warnAboutM2Bug)(options.codec, options.pixelFormat);
    const { task, getLogs } = await innerStitchFramesToVideo(options, remotionRoot);
    const happyPath = task.catch(() => {
        throw new Error(getLogs());
    });
    return Promise.race([
        happyPath,
        new Promise((_resolve, reject) => {
            var _a;
            (_a = options.cancelSignal) === null || _a === void 0 ? void 0 : _a.call(options, () => {
                reject(new Error(make_cancel_signal_1.cancelErrorMessages.stitchFramesToVideo));
            });
        }),
    ]);
};
exports.internalStitchFramesToVideo = internalStitchFramesToVideo;
/**
 * @description Takes a series of images and audio information generated by renderFrames() and encodes it to a video.
 * @see [Documentation](https://www.remotion.dev/docs/renderer/stitch-frames-to-video)
 */
const stitchFramesToVideo = ({ assetsInfo, force, fps, height, width, audioBitrate, audioCodec, cancelSignal, codec, crf, dir, enforceAudioTrack, ffmpegOverride, muted, numberOfGifLoops, onDownload, onProgress, outputLocation, pixelFormat, proResProfile, verbose, videoBitrate, }) => {
    return (0, exports.internalStitchFramesToVideo)({
        assetsInfo,
        audioBitrate: audioBitrate !== null && audioBitrate !== void 0 ? audioBitrate : null,
        audioCodec: audioCodec !== null && audioCodec !== void 0 ? audioCodec : null,
        cancelSignal: cancelSignal !== null && cancelSignal !== void 0 ? cancelSignal : null,
        codec: codec !== null && codec !== void 0 ? codec : codec_1.DEFAULT_CODEC,
        crf: crf !== null && crf !== void 0 ? crf : null,
        dir,
        enforceAudioTrack: enforceAudioTrack !== null && enforceAudioTrack !== void 0 ? enforceAudioTrack : false,
        ffmpegOverride: ffmpegOverride !== null && ffmpegOverride !== void 0 ? ffmpegOverride : null,
        force,
        fps,
        height,
        indent: false,
        muted: muted !== null && muted !== void 0 ? muted : false,
        numberOfGifLoops: numberOfGifLoops !== null && numberOfGifLoops !== void 0 ? numberOfGifLoops : null,
        onDownload: onDownload !== null && onDownload !== void 0 ? onDownload : undefined,
        onProgress,
        outputLocation: outputLocation !== null && outputLocation !== void 0 ? outputLocation : null,
        pixelFormat: pixelFormat !== null && pixelFormat !== void 0 ? pixelFormat : pixel_format_1.DEFAULT_PIXEL_FORMAT,
        proResProfile,
        verbose: verbose !== null && verbose !== void 0 ? verbose : false,
        videoBitrate: videoBitrate !== null && videoBitrate !== void 0 ? videoBitrate : null,
        width,
        preEncodedFileLocation: null,
        preferLossless: false,
    });
};
exports.stitchFramesToVideo = stitchFramesToVideo;
